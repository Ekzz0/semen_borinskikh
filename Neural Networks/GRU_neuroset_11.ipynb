{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c33f9e0-a774-495f-80c4-dc70a4b146fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, Dropout, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2536265-8691-49fa-b27f-f006c6fe9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 88 172\n"
     ]
    }
   ],
   "source": [
    "with open('train_data_true.txt', 'r', encoding='utf-8') as f:\n",
    "    texts_true = f.readlines()\n",
    "    texts_true[0] = texts_true[0].replace('\\ufeff', '') #убираем первый невидимый символ\n",
    "\n",
    "with open('train_data_false.txt', 'r', encoding='utf-8') as f:\n",
    "    texts_false = f.readlines()\n",
    "    texts_false[0] = texts_false[0].replace('\\ufeff', '') #убираем первый невидимый символ\n",
    "\n",
    "texts = texts_true + texts_false\n",
    "count_true = len(texts_true)\n",
    "count_false = len(texts_false)\n",
    "total_lines = count_true + count_false\n",
    "print(count_true, count_false, total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89f2d4e1-15c3-4956-b229-d2f7d55a904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('думайте', 1), ('позитивно', 4), ('и', 50), ('верьте', 3), ('в', 38), ('свою', 4), ('способность', 1), ('достигать', 1), ('отличных', 1), ('результатов', 1)]\n",
      "Думайте позитивно и верьте в свою способность достигать отличных результатов. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxWordsCount = 1000\n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', lower=True, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "dist = list(tokenizer.word_counts.items())\n",
    "print(dist[:10])\n",
    "print(texts[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26fe1d84-4f97-469c-93a1-17e107e5ba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197  54   2 ... 199 200 201]\n",
      " [  0   4 202 ... 205   3  67]\n",
      " [206   3  67 ...   4 208 209]\n",
      " ...\n",
      " [  0  20  62 ...  53 850 851]\n",
      " [  0   0  43 ...  33   1 853]\n",
      " [  0   0   0 ...  70  65 194]]\n"
     ]
    }
   ],
   "source": [
    "max_text_len = 10\n",
    "data = tokenizer.texts_to_sequences(texts)\n",
    "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
    "print(data_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06885d33-6dc0-48ef-afda-c8752746e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( list(tokenizer.word_index.items()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c3381e0-37b3-4478-bf7b-7a80e8f47b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) (172, 2)\n"
     ]
    }
   ],
   "source": [
    "X = data_pad\n",
    "Y = np.array([[1, 0]]*count_true + [[0, 1]]*count_false)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "indeces = np.random.choice(X.shape[0], size=X.shape[0], replace=False)\n",
    "X = X[indeces]\n",
    "Y = Y[indeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5298ced-40ce-4f62-bb4d-b9720eaffc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 10, 128)           128000    \n",
      "                                                                 \n",
      " gru_18 (GRU)                (None, 10, 128)           99072     \n",
      "                                                                 \n",
      " gru_19 (GRU)                (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,450\n",
      "Trainable params: 264,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(maxWordsCount, 128, input_length = max_text_len))\n",
    "model.add(GRU(128, return_sequences=True)) # return_sequences - чтобы выходные знач-я соответствовали входным значениям следующего слоя\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4280888d-fa01-42c7-8b43-46ff62cbc701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7006 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6763 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6683 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6604 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6525 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6445 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6367 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6288 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6209 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6129 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6050 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5970 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5890 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5809 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5728 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5646 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5564 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5480 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5395 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5310 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5223 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5136 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5047 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4957 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4866 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4773 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4679 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4584 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4487 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4389 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4289 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4188 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3982 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3877 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3771 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3663 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3555 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3445 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3335 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3223 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3111 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2999 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2886 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2773 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2660 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2547 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2435 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(X, Y, batch_size=32, epochs=50)\n",
    "\n",
    "#plt.plot(his.history['loss']) # 2й history - словарь, loss - критерий качества\n",
    "#, вычисленный для каждой эпохи\n",
    "#plt.plot(his.history['val_loss'])\n",
    "#plt.grid(True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92793ac3-ebc2-462c-8564-c784e731fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "def sequence_to_text(list_of_indices):\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "985ea89f-b181-40ed-9b9e-72b27230c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мне', 'никогда', 'не', 'выздороветь']\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020AA0AFE4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0.7097477 0.2902523]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t = \"Мне никогда не выздороветь\".lower()\n",
    "data = tokenizer.texts_to_sequences([t])\n",
    "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
    "print( sequence_to_text(data[0]) )\n",
    "\n",
    "res = model.predict(data_pad)\n",
    "print(res, np.argmax(res), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccbec1-7909-46d4-88c7-bbae71780041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
