{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12ec0834-065c-4778-9eef-14d7914d9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Input, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "044f2a70-7315-454b-9af3-e4164db5ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('krovostok.txt', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read()\n",
    "    texts = texts.replace('\\ufeff', '')  # убираем первый невидимый символ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e151f2c3-1e19-4b7e-ad48-02f276a93ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWordsCount = 2000 # максимум слов - maxWordsCount - 1 (пробел) \n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!\"#$%&amp;()*+-/:;<=>@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
    "                      lower=True, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9874be0b-751e-4349-8549-d0e60f283008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('думай', 2), ('позитивно,', 2), ('стакан', 2), ('всегда', 7), ('наполовину', 2), ('полон,', 2), ('чувствуй', 2), ('хорошее,', 2), ('плохого', 3), ('не', 104), ('существует,', 2), ('между', 3), ('нет', 4), ('и', 112), ('да', 16), ('выбор', 3), ('только', 12), ('верь', 2), ('в', 133), ('лучшее,', 2)]\n"
     ]
    }
   ],
   "source": [
    "dist = list(tokenizer.word_counts.items()) # посмотреть частоту встречаемости в тексте\n",
    "print(dist[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "614e206e-666e-41f6-bf28-aac62d547772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer.texts_to_sequences([texts]) # преобразуем текст в последовательность чисел в соотв-и с полученный словарем\n",
    "#res = to_categorical(data[0], num_classes=maxWordsCount) #преобразование в one hot векторы\n",
    "#print(res.shape)\n",
    "\n",
    "res = np.array(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac67fef6-15c4-466a-a1bf-3f466570d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_words = 2 # кол-во слов, на основе которых строится предсказание\n",
    "n = res.shape[0] - inp_words\n",
    "\n",
    "#X = np.array([res[i:i + inp_words, :] for i in range(n)])\n",
    "X = np.array([res[i:i + inp_words] for i in range(n)])\n",
    "#X = np.array([res[i:i + inp_words] for i in range(n)])\n",
    "Y = to_categorical(res[inp_words:], num_classes=maxWordsCount) # должен быть не набором чисел, а набором векторов ?\n",
    "#Y = res[inp_words:] # тензор слов, которые мы должны спрогнозировать\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf89386a-88e0-418b-80cc-d6710db59e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 2, 256)            512000    \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 128)               49280     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2000)              258000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 819,280\n",
      "Trainable params: 819,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Input((inp_words, maxWordsCount)))\n",
    "model.add(Embedding(maxWordsCount, 256, input_length = inp_words))\n",
    "model.add(SimpleRNN(128, activation='tanh'))\n",
    "model.add(Dense(maxWordsCount, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6126aea-af0e-4928-b4fa-7263d977e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 2s 10ms/step - loss: 7.4849 - accuracy: 0.0259\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 6.6712 - accuracy: 0.0450\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 6.0912 - accuracy: 0.0651\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 5.3959 - accuracy: 0.1146\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 4.5657 - accuracy: 0.2166\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 3.7238 - accuracy: 0.3720\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 2.9801 - accuracy: 0.5089\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.3517 - accuracy: 0.6268\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 1.8415 - accuracy: 0.7024\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.4436 - accuracy: 0.7635\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1479 - accuracy: 0.7997\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.9293 - accuracy: 0.8472\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.7609 - accuracy: 0.8691\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6344 - accuracy: 0.8970\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.5338 - accuracy: 0.9130\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.4525 - accuracy: 0.9228\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.3899 - accuracy: 0.9269\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.3413 - accuracy: 0.9264\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.2977 - accuracy: 0.9316\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.2676 - accuracy: 0.9304\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.2428 - accuracy: 0.9362\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.2235 - accuracy: 0.9347\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.2092 - accuracy: 0.9334\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1979 - accuracy: 0.9339\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1884 - accuracy: 0.9344\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1786 - accuracy: 0.9357\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1707 - accuracy: 0.9321\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.1659 - accuracy: 0.9316\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1601 - accuracy: 0.9324\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1570 - accuracy: 0.9326\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9354\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1494 - accuracy: 0.9349\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.1467 - accuracy: 0.9337\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.1442 - accuracy: 0.9374\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1408 - accuracy: 0.9362\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1423 - accuracy: 0.9311\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9319\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1363 - accuracy: 0.9331\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1343 - accuracy: 0.9321\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1322 - accuracy: 0.9337\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1324 - accuracy: 0.9349\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1297 - accuracy: 0.9349\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1295 - accuracy: 0.9311\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1291 - accuracy: 0.9324\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.1251 - accuracy: 0.9359\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.1268 - accuracy: 0.9339\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1244 - accuracy: 0.9364\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1263 - accuracy: 0.9311\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1238 - accuracy: 0.9344\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1229 - accuracy: 0.9349\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16918b7e-80e1-4e86-a637-ed3a559b2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPhrase(texts, str_len=20):\n",
    "    res = texts\n",
    "    data = tokenizer.texts_to_sequences([texts])[0]\n",
    "    for i in range(str_len):\n",
    "        #x = to_categorical(data[i: i + inp_words], num_classes=maxWordsCount)  # преобразуем в One-Hot-encoding\n",
    "        #inp = x.reshape(1, inp_words, maxWordsCount)\n",
    "        x = data[i: i + inp_words]\n",
    "        inp = np.expand_dims(x, axis=0)\n",
    "\n",
    "        pred = model.predict(inp)\n",
    "        indx = pred.argmax(axis=1)[0]\n",
    "        data.append(indx)\n",
    "\n",
    "        res += \" \" + tokenizer.index_word[indx]  # дописываем строку ( преобразовываем индекс обратно в слово) \n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18e522dd-58df-409b-b7c6-c325fa6f4d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "говно моча ебать ударила в голову в 4 активно ругался матом в детском саду девочки впервые показали мне пизду потом школа, вонючая\n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"говно моча\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955cfbc7-8428-489a-9ecb-b67da32bfec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
